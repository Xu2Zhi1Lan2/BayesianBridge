cat(sprintf("Iteration: %d, Satisfied Constraints: YES\n", iter))
} else {
cat(sprintf("Iteration: %d, Satisfied Constraints: NO\n", iter))
}
# 更新障碍参数
mu <- mu / 2
# 检查收敛
if (max(abs(delta)) < tolerance) {
break
}
}
return(list(beta = beta, history = beta_history, iter=iter))
}
# 运行算法
results <- barrier_newton(X, y, beta_init, mu, tolerance, max_iter)
beta_est <- results$beta
beta_history <- as.data.frame(results$history)
# 输出结果
print(beta_est)
# 可视化结果
beta_df <- data.frame(Coefficient = c('beta_0', paste('beta', 1:p, sep='_')), Estimate = beta_est)
ggplot(beta_df, aes(x = Coefficient, y = Estimate)) +
geom_point(stat = "identity") +
theme_minimal() +
labs(title = "Estimates of Beta Coefficients", x = "Coefficient", y = "Estimate")
library(quadprog)
library(ggplot2)
# 读取数据
data <- read.table("exam-problem2.txt", header = FALSE)
# 提取y值和x值
y <- data[, ncol(data)]
X <- as.matrix(data[, -ncol(data)])
n <- nrow(X)
p <- ncol(X)
X <- cbind(1, X)  # 添加一列 1 用于估计 beta_0
# 使用OLS计算初始beta
beta_ols <- solve(t(X) %*% X) %*% t(X) %*% y
beta_ols[beta_ols < 0] <- 0.1  # 将负系数设置为0.1
# 初始参数
beta_init <- beta_ols
mu <- 1
tolerance <- 1e-6
max_iter <- 50
# 牛顿-拉夫森
barrier_newton <- function(X, y, beta_init, mu, tolerance, max_iter) {
beta <- beta_init
beta_history <- matrix(nrow = max_iter, ncol = length(beta))
colnames(beta_history) <- c('beta_0', paste('beta', 1:p, sep='_'))
for (iter in 1:max_iter) {
# 计算残差
residuals <- y - X %*% beta
# 计算梯度
gradient <- -t(X) %*% residuals
gradient[-1] <- gradient[-1] - mu / beta[-1]
# 计算 Hessian 矩阵
Hessian <- t(X) %*% X
Hessian[-1, -1] <- Hessian[-1, -1] + diag(mu / (beta[-1]^2), nrow = p)
# 更新 beta
delta <- solve(Hessian, gradient)
new_beta <- beta - delta
# 检查约束
if (any(new_beta[-1] < 0)) {
new_beta[new_beta < 0] <- 0
satisfied_constraints = FALSE
} else {
satisfied_constraints = TRUE
}
beta <- new_beta
beta_history[iter, ] <- beta
# 检查是否满足约束
if (satisfied_constraints) {
cat(sprintf("Iteration: %d, Satisfied Constraints: YES\n", iter))
} else {
cat(sprintf("Iteration: %d, Satisfied Constraints: NO\n", iter))
}
# 更新障碍参数
mu <- mu / 2
# 检查收敛
if (max(abs(delta)) < tolerance) {
break
}
}
return(list(beta = beta, history = beta_history, iter=iter))
}
# 运行算法
results <- barrier_newton(X, y, beta_init, mu, tolerance, max_iter)
beta_est <- results$beta
beta_history <- as.data.frame(results$history)
# 输出结果
print(beta_est)
# 可视化结果
beta_df <- data.frame(Coefficient = c('beta_0', paste('beta', 1:p, sep='_')), Estimate = beta_est)
ggplot(beta_df, aes(x = Coefficient, y = Estimate)) +
geom_point(stat = "identity") +
theme_minimal() +
labs(title = "Estimates of Beta Coefficients", x = "Coefficient", y = "Estimate")
library(quadprog)
library(ggplot2)
# 读取数据
data <- read.table("exam-problem2.txt", header = FALSE)
# 提取y值和x值
y <- data[, ncol(data)]
X <- as.matrix(data[, -ncol(data)])
n <- nrow(X)
p <- ncol(X)
X <- cbind(1, X)  # 添加一列 1 用于估计 beta_0
# 使用OLS计算初始beta
beta_ols <- solve(t(X) %*% X) %*% t(X) %*% y
beta_ols[beta_ols < 0] <- 0.1  # 将负系数设置为0.1
# 初始参数
beta_init <- beta_ols
mu <- 1
tolerance <- 1e-6
max_iter <- 50
# 牛顿-拉夫森
barrier_newton <- function(X, y, beta_init, mu, tolerance, max_iter) {
beta <- beta_init
beta_history <- matrix(nrow = max_iter, ncol = length(beta))
colnames(beta_history) <- c('beta_0', paste('beta', 1:p, sep='_'))
for (iter in 1:max_iter) {
# 计算残差
residuals <- y - X %*% beta
# 计算梯度
gradient <- -t(X) %*% residuals
gradient[-1] <- gradient[-1] - mu / beta[-1]
# 计算 Hessian 矩阵
Hessian <- t(X) %*% X
Hessian[-1, -1] <- Hessian[-1, -1] + diag(mu / (beta[-1]^2), nrow = p)
# 更新 beta
delta <- solve(Hessian, gradient)
new_beta <- beta - delta
# 检查约束
if (any(new_beta[-1] < 0)) {
satisfied_constraints = FALSE
} else {
satisfied_constraints = TRUE
}
beta <- new_beta
beta_history[iter, ] <- beta
# 检查是否满足约束
if (satisfied_constraints) {
cat(sprintf("Iteration: %d, Satisfied Constraints: YES\n", iter))
} else {
cat(sprintf("Iteration: %d, Satisfied Constraints: NO\n", iter))
}
# 更新障碍参数
mu <- mu / 2
# 检查收敛
if (max(abs(delta)) < tolerance) {
break
}
}
return(list(beta = beta, history = beta_history, iter=iter))
}
# 运行算法
results <- barrier_newton(X, y, beta_init, mu, tolerance, max_iter)
beta_est <- results$beta
beta_history <- as.data.frame(results$history)
# 输出结果
print(beta_est)
# 可视化结果
beta_df <- data.frame(Coefficient = c('beta_0', paste('beta', 1:p, sep='_')), Estimate = beta_est)
ggplot(beta_df, aes(x = Coefficient, y = Estimate)) +
geom_point(stat = "identity") +
theme_minimal() +
labs(title = "Estimates of Beta Coefficients", x = "Coefficient", y = "Estimate")
library(quadprog)
library(ggplot2)
# 读取数据
data <- read.table("exam-problem2.txt", header = FALSE)
# 提取y值和x值
y <- data[, ncol(data)]
X <- as.matrix(data[, -ncol(data)])
n <- nrow(X)
p <- ncol(X)
X <- cbind(1, X)  # 添加一列 1 用于估计 beta_0
# 使用OLS计算初始beta
beta_ols <- solve(t(X) %*% X) %*% t(X) %*% y
beta_ols[beta_ols < 0] <- 0.1  # 将负系数设置为0.1
# 初始参数
beta_init <- beta_ols
mu <- 1
tolerance <- 1e-6
max_iter <- 50
# 牛顿-拉夫森
barrier_newton <- function(X, y, beta_init, mu, tolerance, max_iter) {
beta <- beta_init
beta_history <- matrix(nrow = max_iter, ncol = length(beta))
colnames(beta_history) <- c('beta_0', paste('beta', 1:p, sep='_'))
for (iter in 1:max_iter) {
# 计算残差
residuals <- y - X %*% beta
# 计算梯度
gradient <- -t(X) %*% residuals
gradient[-1] <- gradient[-1] - mu / beta[-1]
# 计算 Hessian 矩阵
Hessian <- t(X) %*% X
Hessian[-1, -1] <- Hessian[-1, -1] + diag(mu / (beta[-1]^2), nrow = p)
# 更新 beta
delta <- solve(Hessian, gradient)
new_beta <- beta - delta
# 检查约束
if (any(new_beta[-1] < 0)) {
satisfied_constraints = FALSE
} else {
satisfied_constraints = TRUE
}
beta <- new_beta
beta_history[iter, ] <- beta
# 检查是否满足约束
if (satisfied_constraints) {
cat(sprintf("Iteration: %d, Satisfied Constraints: YES\n", iter))
} else {
cat(sprintf("Iteration: %d, Satisfied Constraints: NO\n", iter))
}
# 更新障碍参数
mu <- mu / 2
# 检查收敛
if (max(abs(delta)) < tolerance) {
break
}
}
return(list(beta = beta, history = beta_history, iter=iter))
}
# 运行算法
results <- barrier_newton(X, y, beta_init, mu, tolerance, max_iter)
beta_est <- results$beta
beta_history <- as.data.frame(results$history)
# 输出结果
print(beta_est)
print(beta_history)
# 可视化结果
beta_df <- data.frame(Coefficient = c('beta_0', paste('beta', 1:p, sep='_')), Estimate = beta_est)
ggplot(beta_df, aes(x = Coefficient, y = Estimate)) +
geom_point(stat = "identity") +
theme_minimal() +
labs(title = "Estimates of Beta Coefficients", x = "Coefficient", y = "Estimate")
View(beta_history)
View(beta_history)
library(quadprog)
library(ggplot2)
# 读取数据
data <- read.table("exam-problem2.txt", header = FALSE)
# 提取y值和x值
y <- data[, ncol(data)]
X <- as.matrix(data[, -ncol(data)])
n <- nrow(X)
p <- ncol(X)
X <- cbind(1, X)  # 添加一列 1 用于估计 beta_0
# 使用OLS计算初始beta
beta_ols <- solve(t(X) %*% X) %*% t(X) %*% y
beta_ols[beta_ols < 0] <- 0.1  # 将负系数设置为0.1
# 初始参数
beta_init <- beta_ols
mu <- 1
tolerance <- 1e-6
max_iter <- 50
# 牛顿-拉夫森
barrier_newton <- function(X, y, beta_init, mu, tolerance, max_iter) {
beta <- beta_init
beta_history <- matrix(nrow = max_iter, ncol = length(beta))
colnames(beta_history) <- c('beta_0', paste('beta', 1:p, sep='_'))
for (iter in 1:max_iter) {
# 计算残差
residuals <- y - X %*% beta
# 计算梯度
gradient <- -t(X) %*% residuals
gradient[-1] <- gradient[-1] - mu / beta[-1]
# 计算 Hessian 矩阵
Hessian <- t(X) %*% X
Hessian[-1, -1] <- Hessian[-1, -1] + diag(mu / (beta[-1]^2), nrow = p)
# 更新 beta
delta <- solve(Hessian, gradient)
new_beta <- beta - delta
# 检查约束
if (any(new_beta[-1] < 0)) {
satisfied_constraints = FALSE
} else {
satisfied_constraints = TRUE
}
beta <- new_beta
beta_history[iter, ] <- beta
# 检查是否满足约束
if (satisfied_constraints) {
cat(sprintf("Iteration: %d, Satisfied Constraints: YES\n", iter))
} else {
cat(sprintf("Iteration: %d, Satisfied Constraints: NO\n", iter))
}
# 更新障碍参数
mu <- mu / 2
# 检查收敛
if (max(abs(delta)) < tolerance) {
break
}
}
return(list(beta = beta, history = beta_history, iter=iter))
}
# 运行算法
results <- barrier_newton(X, y, beta_init, mu, tolerance, max_iter)
beta_est <- results$beta
# 输出结果
print(beta_est)
print(beta_history)
# 可视化结果
beta_df <- data.frame(Coefficient = c('beta_0', paste('beta', 1:p, sep='_')), Estimate = beta_est)
ggplot(beta_df, aes(x = Coefficient, y = Estimate)) +
geom_point(stat = "identity") +
theme_minimal() +
labs(title = "Estimates of Beta Coefficients", x = "Coefficient", y = "Estimate")
View(beta_history)
View(beta_history)
library(quadprog)
library(ggplot2)
# 读取数据
data <- read.table("exam-problem2.txt", header = FALSE)
# 提取y值和x值
y <- data[, ncol(data)]
X <- as.matrix(data[, -ncol(data)])
n <- nrow(X)
p <- ncol(X)
X <- cbind(1, X)  # 添加一列 1 用于估计 beta_0
# 使用OLS计算初始beta
beta_ols <- solve(t(X) %*% X) %*% t(X) %*% y
beta_ols[beta_ols < 0] <- 0.1  # 将负系数设置为0.1
# 初始参数
beta_init <- beta_ols
mu <- 1
tolerance <- 1e-12
max_iter <- 50
# 牛顿-拉夫森
barrier_newton <- function(X, y, beta_init, mu, tolerance, max_iter) {
beta <- beta_init
beta_history <- matrix(nrow = max_iter, ncol = length(beta))
colnames(beta_history) <- c('beta_0', paste('beta', 1:p, sep='_'))
for (iter in 1:max_iter) {
# 计算残差
residuals <- y - X %*% beta
# 计算梯度
gradient <- -t(X) %*% residuals
gradient[-1] <- gradient[-1] - mu / beta[-1]
# 计算 Hessian 矩阵
Hessian <- t(X) %*% X
Hessian[-1, -1] <- Hessian[-1, -1] + diag(mu / (beta[-1]^2), nrow = p)
# 更新 beta
delta <- solve(Hessian, gradient)
new_beta <- beta - delta
# 检查约束
if (any(new_beta[-1] < 0)) {
satisfied_constraints = FALSE
} else {
satisfied_constraints = TRUE
}
beta <- new_beta
beta_history[iter, ] <- beta
# 检查是否满足约束
if (satisfied_constraints) {
cat(sprintf("Iteration: %d, Satisfied Constraints: YES\n", iter))
} else {
cat(sprintf("Iteration: %d, Satisfied Constraints: NO\n", iter))
}
# 更新障碍参数
mu <- mu / 2
# 检查收敛
if (max(abs(delta)) < tolerance) {
break
}
}
return(list(beta = beta, history = beta_history, iter=iter))
}
# 运行算法
results <- barrier_newton(X, y, beta_init, mu, tolerance, max_iter)
beta_est <- results$beta
library(quadprog)
library(ggplot2)
# 读取数据
data <- read.table("exam-problem2.txt", header = FALSE)
# 提取y值和x值
y <- data[, ncol(data)]
X <- as.matrix(data[, -ncol(data)])
n <- nrow(X)
p <- ncol(X)
X <- cbind(1, X)  # 添加一列 1 用于估计 beta_0
# 使用OLS计算初始beta
beta_ols <- solve(t(X) %*% X) %*% t(X) %*% y
beta_ols[beta_ols < 0] <- 0.1  # 将负系数设置为0.1
# 初始参数
beta_init <- beta_ols
mu <- 10
tolerance <- 1e-12
max_iter <- 50
# 牛顿-拉夫森
barrier_newton <- function(X, y, beta_init, mu, tolerance, max_iter) {
beta <- beta_init
beta_history <- matrix(nrow = max_iter, ncol = length(beta))
colnames(beta_history) <- c('beta_0', paste('beta', 1:p, sep='_'))
for (iter in 1:max_iter) {
# 计算残差
residuals <- y - X %*% beta
# 计算梯度
gradient <- -t(X) %*% residuals
gradient[-1] <- gradient[-1] - mu / beta[-1]
# 计算 Hessian 矩阵
Hessian <- t(X) %*% X
Hessian[-1, -1] <- Hessian[-1, -1] + diag(mu / (beta[-1]^2), nrow = p)
# 更新 beta
delta <- solve(Hessian, gradient)
new_beta <- beta - delta
# 检查约束
if (any(new_beta[-1] < 0)) {
satisfied_constraints = FALSE
} else {
satisfied_constraints = TRUE
}
beta <- new_beta
beta_history[iter, ] <- beta
# 检查是否满足约束
if (satisfied_constraints) {
cat(sprintf("Iteration: %d, Satisfied Constraints: YES\n", iter))
} else {
cat(sprintf("Iteration: %d, Satisfied Constraints: NO\n", iter))
}
# 更新障碍参数
mu <- mu / 2
# 检查收敛
if (max(abs(delta)) < tolerance) {
break
}
}
return(list(beta = beta, history = beta_history, iter=iter))
}
# 运行算法
results <- barrier_newton(X, y, beta_init, mu, tolerance, max_iter)
beta_est <- results$beta
# 输出结果
print(beta_est)
print(beta_history)
# 可视化结果
beta_df <- data.frame(Coefficient = c('beta_0', paste('beta', 1:p, sep='_')), Estimate = beta_est)
ggplot(beta_df, aes(x = Coefficient, y = Estimate)) +
geom_point(stat = "identity") +
theme_minimal() +
labs(title = "Estimates of Beta Coefficients", x = "Coefficient", y = "Estimate")
library(quadprog)
library(ggplot2)
# 读取数据
data <- read.table("exam-problem2.txt", header = FALSE)
# 提取y值和x值
y <- data[, ncol(data)]
X <- as.matrix(data[, -ncol(data)])
n <- nrow(X)
p <- ncol(X)
X <- cbind(1, X)  # 添加一列 1 用于估计 beta_0
# 使用OLS计算初始beta
beta_ols <- solve(t(X) %*% X) %*% t(X) %*% y
beta_ols[beta_ols < 0] <- 0.1  # 将负系数设置为0.1
# 初始参数
beta_init <- beta_ols
mu <- 10
tolerance <- 1e-12
max_iter <- 50
# 牛顿-拉夫森
barrier_newton <- function(X, y, beta_init, mu, tolerance, max_iter) {
beta <- beta_init
beta_history <- matrix(nrow = max_iter, ncol = length(beta))
colnames(beta_history) <- c('beta_0', paste('beta', 1:p, sep='_'))
for (iter in 1:max_iter) {
# 计算残差
residuals <- y - X %*% beta
# 计算梯度
gradient <- -t(X) %*% residuals
gradient[-1] <- gradient[-1] - mu / beta[-1]
# 计算 Hessian 矩阵
Hessian <- t(X) %*% X
Hessian[-1, -1] <- Hessian[-1, -1] + diag(mu / (beta[-1]^2), nrow = p)
# 更新 beta
delta <- solve(Hessian, gradient)
new_beta <- beta - delta
# 检查约束
if (any(new_beta[-1] < 0)) {
satisfied_constraints = FALSE
} else {
satisfied_constraints = TRUE
}
beta <- new_beta
beta_history[iter, ] <- beta
# 检查是否满足约束
if (satisfied_constraints) {
cat(sprintf("Iteration: %d, Satisfied Constraints: YES\n", iter))
} else {
cat(sprintf("Iteration: %d, Satisfied Constraints: NO\n", iter))
}
# 更新障碍参数
mu <- mu / 2
# 检查收敛
if (max(abs(delta)) < tolerance) {
break
}
}
return(list(beta = beta, history = beta_history, iter=iter))
}
# 运行算法
results <- barrier_newton(X, y, beta_init, mu, tolerance, max_iter)
beta_est <- results$beta
# 输出结果
print(beta_est)
print(beta_history)
# 可视化结果
beta_df <- data.frame(Coefficient = c('beta_0', paste('beta', 1:p, sep='_')), Estimate = beta_est)
ggplot(beta_df, aes(x = Coefficient, y = Estimate)) +
geom_point(stat = "identity") +
theme_minimal() +
labs(title = "Estimates of Beta Coefficients", x = "Coefficient", y = "Estimate")
